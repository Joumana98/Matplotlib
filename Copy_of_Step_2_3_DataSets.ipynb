{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Step_2_3_DataSets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6OzHNTtkkDh",
        "colab_type": "code",
        "outputId": "0ac3f3b0-fe39-4d2f-a360-e19fe7404faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.2.0rc2)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0rc0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.18.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (1.6.0.post2)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (46.0.0)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LGu1Y30iX3K",
        "colab_type": "code",
        "outputId": "c59751c5-7ccb-450e-aa60-afde242463f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfMgLG8XzyFi",
        "colab_type": "code",
        "outputId": "fef23292-deb7-4ceb-9056-e58018c4cba8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) # the simplest way to create a dataset is to create it from a python list:\n",
        "for element in dataset: \n",
        "  print(element)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMKDkbwtzyFw",
        "colab_type": "code",
        "outputId": "2e201620-2e07-4712-970b-595ff1aac9fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])  # To process lines from files, use tf.data.TextLineDataset0\n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.map(lambda x: x*2) #  Once you have a dataset, you can apply transformations to prepare the data for your model:\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsG6sLe8zyF7",
        "colab_type": "code",
        "outputId": "10f48043-72d6-4456-f443-1103325a9d88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Creates a dataset of a step-separated range of values\n",
        "list(dataset.range(5).as_numpy_iterator()) \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUhg1S38zyGJ",
        "colab_type": "code",
        "outputId": "3055af7a-0dc9-4a79-e163-1055884fb58c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(2, 5).as_numpy_iterator()) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6rOGVWbzyGT",
        "colab_type": "code",
        "outputId": "8605cc20-0e8b-45b6-a8c0-8c781358276a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, 2).as_numpy_iterator()) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGFteqpazyGf",
        "colab_type": "code",
        "outputId": "61fd35fa-97db-4fc1-a4d9-8d0913629b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(1, 5, -2).as_numpy_iterator()) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbYu1EO-zyGt",
        "colab_type": "code",
        "outputId": "91b73e01-3f34-4c1a-feb4-d32b6f474593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1, -2).as_numpy_iterator()) "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR1_DHNnzyG5",
        "colab_type": "code",
        "outputId": "5fefbfe0-3ddd-406a-da19-9936cfdd0864",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "list(dataset.range(5, 1).as_numpy_iterator()) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbnpLAgHzyHD",
        "colab_type": "code",
        "outputId": "9786f0dc-5437-4f5a-f856-458ae6fc2f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Reduces the input dataset to a single element.\n",
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy() \n",
        "#reduce(initial_state, reduce_func)\n",
        "#Reduces the input dataset to a single element.\n",
        "#The transformation calls reduce_func successively on every element \n",
        "#of the input dataset until the dataset is exhausted, \n",
        "#aggregating information in its internal state. \n",
        "#The initial_state argument is used for the initial state \n",
        "# and the final state is returned as the result."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T3YUFfmzyHJ",
        "colab_type": "code",
        "outputId": "511a684b-abff-4cee-e733-e8e39e53a609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFKN4_8ozyHR",
        "colab_type": "code",
        "outputId": "af861316-8ac4-498a-ef01-eb78bea351cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.repeat(3) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#Repeats this dataset so each original value is seen count times."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 1, 2, 3, 1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5_YKF1zyHV",
        "colab_type": "code",
        "outputId": "26bdf190-41a4-4f4f-9a90-dc730b1c8da7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "dataset = dataset.map(lambda x: x + 1) \n",
        "#  Maps map_func across the elements of this dataset.\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbIzPUlFzyHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.range(5) \n",
        "# `map_func` takes a single argument of type `tf.Tensor` with the same \n",
        "# shape and dtype. \n",
        "result = dataset.map(lambda x: x + 1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VftZ3OsCzyHi",
        "colab_type": "code",
        "outputId": "588413b1-7fce-4e76-ffc2-47d7cac25c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Each element is a tuple containing two `tf.Tensor` objects. \n",
        "elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz)\")] \n",
        "dataset = tf.data.Dataset.from_generator( \n",
        "    lambda: elements, (tf.int32, tf.string)) \n",
        "# `map_func` takes two arguments of type `tf.Tensor`. This function \n",
        "# projects out just the first component. \n",
        "result = dataset.map(lambda x_int, y_str: x_int) \n",
        "list(result.as_numpy_iterator()) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5vIHVXzyHn",
        "colab_type": "code",
        "outputId": "88a5264c-236c-4d0f-c4d2-636f0783cb24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import itertools \n",
        "import collections\n",
        "a = 1 # Integer element \n",
        "b = 2.0 # Float element \n",
        "c = (1, 2) # Tuple element with 2 components \n",
        "d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components \n",
        "Point = collections.namedtuple(\"Point\", [\"x\", \"y\"]) # doctest: +SKIP Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
        "e = Point(1, 2) # Named tuple # doctest: +SKIP \n",
        "f = tf.data.Dataset.range(10) # Dataset element \n",
        "e                  # readable __repr__ with a name=value style"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Point(x=1, y=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhhElNRzyHu",
        "colab_type": "code",
        "outputId": "bfaeb4a4-a643-4509-8532-43ae681db91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e[0] + e[1] # indexable like the plain tuple (1, 2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrNyJS1bzyH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = e                # unpack like a regular tuple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFvKTEPjzyH-",
        "colab_type": "code",
        "outputId": "c029639e-6b30-4260-d848-8fb274837305",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x, y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nezjMwkPzyIC",
        "colab_type": "code",
        "outputId": "16b8807d-74df-4f1e-873e-16a32bf858c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "e.x + e.y               # fields also accessible by name"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIR0pqMqzyII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]).element_spec  # element_spec: The type specification of an element of this dataset."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isc_TOOezyIM",
        "colab_type": "code",
        "outputId": "2c71b9ab-761b-44a2-d403-ee96f5f56f30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(100) \n",
        "def dataset_fn(ds): # transformation_func: A function that takes one Dataset argument and returns a Dataset.\n",
        "  return ds.filter(lambda x: x < 5) \n",
        "dataset = dataset.apply(dataset_fn) # apply enables chaining of custom Dataset transformations, which are represented as functions that take one Dataset argument and return a transformed Dataset.\n",
        "list(dataset.as_numpy_iterator()) # Returns an iterator which converts all elements of the dataset to numpy."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJRgCFSzyIU",
        "colab_type": "code",
        "outputId": "2ee347b7-878d-49d6-c3d0-70f7e2268f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztE1DAOzyIZ",
        "colab_type": "code",
        "outputId": "72b4db6b-952c-4bc3-f555-826ccb54f138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "print(list(dataset.as_numpy_iterator())) "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6ZUx9DDzyIe",
        "colab_type": "code",
        "outputId": "944173d1-3c5b-4364-e0df-9c4becccc1f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), \n",
        "                                              'b': [5, 6]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, # as_numpy_iterator() will preserve the nested structure of dataset elements.\n",
        "                                      {'a': (2, 4), 'b': 6}] "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaiusP8jzyIl",
        "colab_type": "code",
        "outputId": "b7b1ce5a-fdb7-4aad-858e-542b4d9acbf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8)  \n",
        "dataset = dataset.batch(3) # Combines consecutive elements of this dataset into batches.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtqBv9gXzyIr",
        "colab_type": "code",
        "outputId": "c03ab93b-c066-4e9b-cf31-7199e4c28e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(8) \n",
        "dataset = dataset.batch(3, drop_remainder=True) #  If your program depends on the batches having the same outer dimension, you should set the drop_remainder argument to True to prevent the smaller batch from being produced.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0, 1, 2]), array([3, 4, 5])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioklpGSKzyIx",
        "colab_type": "code",
        "outputId": "392e6e9e-47b7-4c0f-f011-16516752d046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(5) \n",
        "dataset = dataset.map(lambda x: x**2) \n",
        "dataset = dataset.cache() #Caches the elements in this dataset.\n",
        "# The first time reading through the data will generate the data using \n",
        "# `range` and `map`. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XtuMhhszyI4",
        "colab_type": "code",
        "outputId": "81adb970-619d-45ab-fac6-596f6c93c32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Subsequent iterations read from the cache. \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 4, 9, 16]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOPLCdnzyI8",
        "colab_type": "code",
        "outputId": "0cd3da87-f848-4af9-a420-af3704b94ee9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ] \n",
        "b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ] \n",
        "ds = a.concatenate(b) # Creates a Dataset by concatenating the given dataset with this dataset.\n",
        "list(ds.as_numpy_iterator())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmTwIWfHzyJA",
        "colab_type": "code",
        "outputId": "777ecf0e-1a45-46ba-d147-bab8841f13e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVT4COLwzyJJ",
        "colab_type": "code",
        "outputId": "1fe90b39-c2c9-496e-be86-f8e84468e6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a 1D tensor produces scalar tensor elements. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QZGsfQJzyJP",
        "colab_type": "code",
        "outputId": "2a9a0620-67ec-46d8-85ac-28535c7cf285",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Slicing a tuple of 1D tensors produces tuple elements containing \n",
        "# scalar tensors. \n",
        "dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6])) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 3, 5), (2, 4, 6)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzTLa731zyJT",
        "colab_type": "code",
        "outputId": "562eaa94-6ab8-40f2-83c8-488fde4b5025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Dictionary structure is also preserved. \n",
        "dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]}) \n",
        "list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3}, \n",
        "                                      {'a': 2, 'b': 4}]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtKU5zUJzyJg",
        "colab_type": "code",
        "outputId": "da2596c4-e241-43fb-8b64-dbe3962e4630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Two tensors can be combined into one Dataset object. \n",
        "features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor \n",
        "labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor \n",
        "dataset = dataset.from_tensor_slices((features, labels)) \n",
        "# Both the features and the labels tensors can be converted \n",
        "# to a Dataset object separately and combined after. \n",
        "features_dataset = dataset.from_tensor_slices(features) \n",
        "labels_dataset = dataset.from_tensor_slices(labels) \n",
        "dataset = dataset.zip((features_dataset, labels_dataset)) \n",
        "# A batched feature and label set can be converted to a Dataset \n",
        "# in similar fashion. \n",
        "batched_features = tf.constant([[[1, 3], [2, 3]], \n",
        "                                [[2, 1], [1, 2]], \n",
        "                                [[3, 3], [3, 2]]], shape=(3, 2, 2)) \n",
        "batched_labels = tf.constant([['A', 'A'], \n",
        "                              ['B', 'B'], \n",
        "                              ['A', 'B']], shape=(3, 2, 1)) \n",
        "dataset = dataset.from_tensor_slices((batched_features, batched_labels)) \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([[1, 3],\n",
            "       [2, 3]], dtype=int32), array([[b'A'],\n",
            "       [b'A']], dtype=object))\n",
            "(array([[2, 1],\n",
            "       [1, 2]], dtype=int32), array([[b'B'],\n",
            "       [b'B']], dtype=object))\n",
            "(array([[3, 3],\n",
            "       [3, 2]], dtype=int32), array([[b'A'],\n",
            "       [b'B']], dtype=object))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxILufvzyJj",
        "colab_type": "code",
        "outputId": "2a19a0af-119d-40e2-a9c3-00fe6f3e3135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.enumerate(start=5) #Enumerates the elements of this dataset.\n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5, 1)\n",
            "(6, 2)\n",
            "(7, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0e4NzCSzyJo",
        "colab_type": "code",
        "outputId": "c9495a20-d7bf-4b27-d857-c28b3e1cede8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# The nested structure of the input dataset determines the structure of \n",
        "# elements in the resulting dataset. \n",
        "dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)]) \n",
        "dataset = dataset.enumerate() \n",
        "for element in dataset.as_numpy_iterator(): \n",
        "  print(element) "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, array([7, 8], dtype=int32))\n",
            "(1, array([ 9, 10], dtype=int32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKFU1g0izyJw",
        "colab_type": "code",
        "outputId": "cee4d54a-00a3-4183-80c8-0adbde8ecfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3]) \n",
        "dataset = dataset.filter(lambda x: x < 3) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xl2FTn8rzyJ_",
        "colab_type": "code",
        "outputId": "943d800d-8521-425b-aff5-c8043f2b7b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# `tf.math.equal(x, y)` is required for equality comparison \n",
        "def filter_fn(x): \n",
        "  return tf.math.equal(x, 1) \n",
        "dataset = dataset.filter(filter_fn) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0y-_EExzyKC",
        "colab_type": "code",
        "outputId": "972c9c54-0ebe-495f-dc3c-4c9896c98bc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = dataset.from_tensor_slices([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) \n",
        "dataset = dataset.flat_map(lambda x: dataset.from_tensor_slices(x)) # Use flat_map if you want to make sure that the order of your dataset stays the same. \n",
        "#For example, to flatten a dataset of batches into a dataset of their elements\n",
        "list(dataset.as_numpy_iterator())"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bijMSAjxzyKH",
        "colab_type": "code",
        "outputId": "218f536b-5470-4f1c-84b3-b60374a192df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def gen(): \n",
        "  for i in itertools.count(1): \n",
        "    yield (i, [1] * i) \n",
        "dataset = tf.data.Dataset.from_generator(gen,  #Creates a Dataset whose elements are generated by generator.\n",
        "     (tf.int64, tf.int64), \n",
        "     (tf.TensorShape([]), tf.TensorShape([None]))) \n",
        "list(dataset.take(3).as_numpy_iterator())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, array([1])), (2, array([1, 1])), (3, array([1, 1, 1]))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alq0SFvIzyKN",
        "colab_type": "code",
        "outputId": "fe47b265-9223-4d0e-f198-f03bbb87d49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors([1, 2, 3]) # Creates a Dataset with a single element, comprising the given tensors.\n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2, 3], dtype=int32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QGg5cIfzyKT",
        "colab_type": "code",
        "outputId": "22ab9758-7d4c-4355-e83b-9a2100ab6da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A')) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(array([1, 2, 3], dtype=int32), b'A')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy3Og8tFzyKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess 4 files concurrently, and interleave blocks of 16 records \n",
        "# from each file. \n",
        "filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\", \n",
        "             \"/var/data/file3.txt\", \"/var/data/file4.txt\"] \n",
        "dataset = tf.data.Dataset.from_tensor_slices(filenames) \n",
        "def parse_fn(filename): \n",
        "  return tf.data.Dataset.range(10) \n",
        "dataset = dataset.interleave(lambda x: \n",
        "    tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1), \n",
        "    cycle_length=4, block_length=16) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv5DZ7qszyKk",
        "colab_type": "code",
        "outputId": "f00e53cc-cf93-4647-80f2-9e9666be7ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "dataset = dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ] \n",
        "# NOTE: New lines indicate \"block\" boundaries. \n",
        "dataset = dataset.interleave( \n",
        "    lambda x: dataset.from_tensors(x).repeat(6), \n",
        "    cycle_length=2, block_length=4) \n",
        "list(dataset.as_numpy_iterator()) \n",
        "#The cycle_length and block_length arguments control the order in which elements are produced. \n",
        "#cycle_length controls the number of input elements that are processed concurrently.\n",
        "#cycle_length input elements, open iterators on the returned Dataset objects, \n",
        "# and cycle through them producing block_length consecutive elements from each iterator, "
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 4,\n",
              " 3,\n",
              " 3,\n",
              " 4,\n",
              " 4,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5,\n",
              " 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bvgKAHdzyKq",
        "colab_type": "code",
        "outputId": "e8bab26c-cd7c-44d2-da2b-fef9fd0a4058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "elements = [[1, 2], \n",
        "            [3, 4, 5], \n",
        "            [6, 7], \n",
        "            [8]] \n",
        "A = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32) \n",
        "# Pad to the smallest per-batch size that fits all elements. \n",
        "B = A.padded_batch(2, padded_shapes=[None]) \n",
        "for element in B.as_numpy_iterator(): \n",
        "  print(element) \n",
        "#Combines consecutive elements of this dataset into padded batches.\n",
        "#This transformation combines multiple consecutive elements of the input dataset into a single element."
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 0]\n",
            " [3 4 5]]\n",
            "[[6 7]\n",
            " [8 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMQojFYZzyKz",
        "colab_type": "code",
        "outputId": "f4f7c6ad-635f-4a9b-92ba-141459328a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset = tf.data.Dataset.range(3) \n",
        "dataset = dataset.prefetch(2) \n",
        "list(dataset.as_numpy_iterator()) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgwxDxGwzyK-",
        "colab_type": "code",
        "outputId": "7a01cdfb-3759-4c5a-9ff1-b3c58e095711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "a = tf.add(3, 5)\n",
        "print(a)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(8, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gsFWi9kzyLF",
        "colab_type": "code",
        "outputId": "a247aec8-1c7d-4207-a3e7-46bb266199ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a = tf.constant([[3, 5], [4, 8]])\n",
        "b = tf.constant([[1, 6], [2, 9]])\n",
        "tf.math.add_n([a, b, a])  # [[7, 16], [10, 25]]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 7, 16],\n",
              "       [10, 25]], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcGaF2EPzyLJ",
        "colab_type": "code",
        "outputId": "0073f5a7-facc-4f51-f40e-2341a61e2d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "     a = tf.constant(5.0)\n",
        "     b = tf.constant(6.0)\n",
        "     c = tf.add(a, b)\n",
        "     # Evaluate the tensor `c`.\n",
        "     print(ses.run(c))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmRvvl9fzyLT",
        "colab_type": "code",
        "outputId": "46841c4c-fb47-41ba-ffa1-25625b48d9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "x = 2\n",
        "y = 3\n",
        "op1 = tf.add(x, y)\n",
        "op2 = tf.multiply(x, y)\n",
        "op3 = tf.pow(op2, op1)\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    op3 = sess.run(op3)\n",
        "print(op3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-17e52c60323e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mop3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 958\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1166\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \"\"\"\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;31m# Did not find anything.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[1;32m    303\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[0;32m--> 305\u001b[0;31m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[1;32m    306\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         raise TypeError('Fetch argument %r has invalid type %r, '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3511\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3512\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3514\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[0;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[1;32m   3588\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m       \u001b[0;31m# Actually obj is just the object it's referring to.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m     raise AttributeError(\n\u001b[0;32m-> 1118\u001b[0;31m         \"Tensor.graph is meaningless when eager execution is enabled.\")\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Tensor.graph is meaningless when eager execution is enabled.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: Current TensorFlow version is 2.2.0-rc2. To use TF 1.x instead,\nrestart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before\nyou run \"import tensorflow\".\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm6tsdbhzyLb",
        "colab_type": "code",
        "outputId": "79e0277f-2742-44dc-bec6-cee8f4f81a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Launch the graph in a session.\n",
        "with tf.compat.v1.Session() as ses:\n",
        "     # Build a graph.\n",
        "      x = 2\n",
        "      y = 3\n",
        "      add_op = tf.add(x, y)\n",
        "      mul_op = tf.multiply(x, y)\n",
        "      useless = tf.multiply(x, add_op)\n",
        "      pow_op = tf.pow(add_op, mul_op)\n",
        "      # Evaluate the tensor `c`.\n",
        "      print(ses.run(pow_op))\n",
        "# Using the `close()` method.\n",
        "ses.close()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0XxLTMPzyLi",
        "colab_type": "code",
        "outputId": "2312094c-bfd6-486d-e7d2-be5017310284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Creates a graph.\n",
        "physical_devices = tf.config.list_physical_devices('GPU') \n",
        "try: \n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
        "except: \n",
        "  # Invalid device or cannot modify virtual devices once initialized. \n",
        "  pass \n",
        "  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='a')\n",
        "  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], name='b')\n",
        "  c = tf.multiply(a, b)\n",
        "# Creates a session with log_device_placement set to True.\n",
        "#sess = tf.compat.v1.Session(config=tf.config.experimental(log_device_placement=True))\n",
        "# Runs the op.\n",
        "print(c)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 1.  4.  9. 16. 25. 36.], shape=(6,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTWoWwNhzyLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}